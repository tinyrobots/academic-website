+++
title = "Invited talk, MPI Leipzig"

# Schedule page publish date (NOT talk date).
publishDate = 2017-01-01T00:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Katherine R. Storrs"]

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date = 2020-06-05T11:00:00
date_end = 2020-06-05T12:30:00
all_day = false

# Location of event.
location = "Virtual talk"

# Name of event and optional event URL.
event = "Learning About the World By Learning About Images"
event_url = ""

# Abstract. What's your talk about?
abstract = "Computational visual neuroscience has come a long way in the past 10 years. For the first time, we have fully explicit, image-computable models that can recognise objects with near-human accuracy, and predict brain activity in high-level visual regions. I will present evidence that diverse deep neural network architectures all predict brain representations well, and that task-training and subsequent reweighting of model features is critical to this high performance. However, vision is not yet explained. The most successful models are deep neural networks that have been supervised using ground-truth labels for millions of images. Brains have no such access to the ground truth, and must instead learn directly from sensory data. Unsupervised deep learning, in which networks learn statistical regularities in their data by compressing, extrapolating or predicting images and videos, is an ecologically feasible alternative. I will show that an unsupervised deep network trained on an environment of 3D rendered surfaces with varying shape, material and illumination, spontaneously comes to encode those factors in its internal representations. Most strikingly, the network makes patterns of errors in its perception of material which follow, on an image-by-image basis, the patterns of errors made by human observers. Unsupervised deep learning may provide a coherent framework for how our perceptual dimensions arise."

# Summary. An optional shortened abstract.
summary = ""

# Is this a featured talk? (true/false)
featured = true

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["display"]

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Optional filename of your slides within your talk folder or a URL.
url_slides = ""

# Projects (optional).
#   Associate this talk with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Links (optional).
url_pdf = ""
url_video = ""
url_code = ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Left"
+++
