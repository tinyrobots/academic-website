+++
title = "Invited talk, Vrije Universiteit Amsterdam"

# Schedule page publish date (NOT talk date).
publishDate = 2017-01-01T00:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Katherine R. Storrs"]

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date = 2020-12-04T16:00:00
date_end = 2020-12-04T17:00:00
all_day = false

# Location of event.
location = "Virtual talk"

# Name of event and optional event URL.
event = "Learning About the World By Learning About Images"
event_url = ""

# Abstract. What's your talk about?
abstract = "Models of vision have come far in the past 10 years. Deep neural networks can recognise objects with near-human accuracy, and predict brain activity in high-level visual regions. However, most networks require supervised training using ground-truth labels for millions of images, whereas brains must somehow learn from sensory experience alone. We have been using unsupervised deep learning, combined with computer-rendered artificial environments, as a framework to understand how brains learn rich scene representations without ground-truth information about the world. An unsupervised generative neural network spontaneously clustered images according to scene properties like material and illumination, despite receiving no explicit information about them. Strikingly, the resulting representations also predicted specific patterns of 'successes' and 'errors' in human perception, like the tendency for bumpier surfaces to appear glossier than flatter ones with identical materials. A supervised network and diverse alternative models failed. We think that perceptual dimensions, like 'glossiness,' that seem to estimate properties of the physical world, can emerge spontaneously by learning to efficiently encode sensory data â€“ indeed, unsupervised learning principles might underlie many perceptual dimensions in vision and beyond!"

# Summary. An optional shortened abstract.
summary = ""

# Is this a featured talk? (true/false)
featured = true

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["display"]

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references 
#   `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides = ""

# Optional filename of your slides within your talk folder or a URL.
url_slides = ""

# Projects (optional).
#   Associate this talk with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["deep-learning"]` references 
#   `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects = []

# Links (optional).
url_pdf = ""
url_video = ""
url_code = ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = "Left"
+++
